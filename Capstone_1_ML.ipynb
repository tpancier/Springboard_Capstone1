{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8378, 74)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "dating_data_clean = pd.read_csv('dating_data_clean.csv')\n",
    "dating_data_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Changing variables to category type **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dating_data_clean['match'] = dating_data_clean['match'].astype('category')\n",
    "dating_data_clean['dec'] = dating_data_clean['dec'].astype('category')\n",
    "dating_data_clean['dec_o'] = dating_data_clean['dec_o'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Predicting based on important attributes at sign up\n",
    "\n",
    "\n",
    "Each participant ranked the attributes (attractive, sincere, intelligent, ambitious, fun, shared interests) assigning a scale from 1 to 10 based on what is important for them in a partner.\n",
    "The code below predicts a match based on this ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: KNN classifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using all 6 attributes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_1_1 = dating_data_clean[['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']]\n",
    "three_1_1 = dating_data_clean[['attr1_1', 'fun1_1', 'shar1_1']]\n",
    "two_1_1 = dating_data_clean[['attr1_1', 'shar1_1']]\n",
    "target = np.ravel(dating_data_clean['match'])\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "## For all features:\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(all_1_1, target, test_size = 0.2, random_state=42, stratify=target)\n",
    "\n",
    "knn_a = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_a = GridSearchCV(knn_a, param_grid, cv=5)\n",
    "\n",
    "# train for all features:\n",
    "knn_cv_a.fit(X_train_a, y_train_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question for Andrei: what does stratify do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 26}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best parameter\n",
    "knn_cv_a.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83572068039391223"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best score\n",
    "knn_cv_a.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on training data to compare with score\n",
    "y_pred_all = knn_cv_a.predict(X_train_a)\n",
    "y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83661593554162939"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train_all = knn_cv_a.score(X_train_a, y_train_a)\n",
    "accuracy_train_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question to Andrei: is score different than my prediction on the training data because of cross validation 5-fold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83591885441527447"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_all = knn_cv_a.predict(X_test_a)\n",
    "accuracy_all = knn_cv_a.score(X_test_a, y_test_a)\n",
    "accuracy_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 3 attributes identified in EDA with major correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For 3 features:\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(three_1_1, target, test_size = 0.2, random_state=42, stratify=target)\n",
    "\n",
    "knn_3 = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_3 = GridSearchCV(knn_3, param_grid, cv=5)\n",
    "\n",
    "# train for 3 features:\n",
    "knn_cv_3.fit(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 20}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83497463443748132"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_3 = knn_cv_3.predict(X_test_3)\n",
    "accuracy_3 = knn_cv_3.score(X_test_3, y_test_3)\n",
    "accuracy_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 2 attributes identified in EDA with major correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For 2 features\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(two_1_1, target, test_size = 0.2, random_state=42, stratify=target)\n",
    "\n",
    "knn_2 = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_2 = GridSearchCV(knn_2, param_grid, cv=5)\n",
    "\n",
    "# train for 2 features:\n",
    "knn_cv_2.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 22}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83527305282005371"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_2 = knn_cv_2.predict(X_test_2)\n",
    "accuracy_2 = knn_cv_2.score(X_test_2, y_test_2)\n",
    "accuracy_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 1 attribute identified in EDA with major correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For 1 feature:\n",
    "\n",
    "one_1_1 = dating_data_clean[['attr1_1']]\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(one_1_1, target, test_size = 0.2, random_state=42, stratify=target)\n",
    "\n",
    "knn_1 = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_1 = GridSearchCV(knn_1, param_grid, cv=5)\n",
    "\n",
    "# train for all features:\n",
    "knn_cv_1.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 22}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83527305282005371"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_1 = knn_cv_1.predict(X_test_1)\n",
    "accuracy_1 = knn_cv_1.score(X_test_1, y_test_1)\n",
    "accuracy_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question to Andrei: is it possible that 3, 2 and 1 features give exactly the same score? Should best score or test data accuracy be used as indicator of better model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: model performs better with all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using all 6 attributes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## For all features:\n",
    "\n",
    "clf_a = MultinomialNB().fit(X_train_a, y_train_a)\n",
    "\n",
    "clf_a.score(X_test_a, y_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_a = clf_a.predict(X_test_a)\n",
    "accuracy_a = clf_a.score(X_test_a, y_test_a)\n",
    "accuracy_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 3 attributes identified in EDA with major correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3 features:\n",
    "\n",
    "clf_3 = MultinomialNB().fit(X_train_3, y_train_3)\n",
    "\n",
    "clf_3.score(X_test_3, y_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_3 = clf_3.predict(X_test_3)\n",
    "accuracy_3 = clf_3.score(X_test_3, y_test_3)\n",
    "accuracy_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 2 attributes identified in EDA with major correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2 features:\n",
    "\n",
    "clf_2 = MultinomialNB().fit(X_train_2, y_train_2)\n",
    "\n",
    "clf_2.score(X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2 = clf_2.predict(X_test_2)\n",
    "accuracy_2 = clf_2.score(X_test_2, y_test_2)\n",
    "accuracy_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 1 attribute identified in EDA with major correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1 feature:\n",
    "\n",
    "clf_1 = MultinomialNB().fit(X_train_1, y_train_1)\n",
    "\n",
    "clf_1.score(X_test_1, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1 = clf_1.predict(X_test_1)\n",
    "accuracy_1 = clf_1.score(X_test_1, y_test_1)\n",
    "accuracy_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question for Andrei: could all combination of features give the same score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Observation: KNN with 4 features and n = 26 gave better score predicting the test data than NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Predicting based on self assessment at sign up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each participant ranked themselves based on the same attributes assigning a scale from 1 to 10.\n",
    "The code below predicts a match based on this ranking, which could be an indication of how self-esteem or self awareness influences a match.\n",
    "\n",
    "Shared interests is not a relevant attribute in this set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: KNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using all 5 attributes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_3_1 = dating_data_clean[['attr3_1', 'sinc3_1', 'intel3_1', 'fun3_1', 'amb3_1']]\n",
    "\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "## For all features:\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(all_3_1, target, test_size = 0.2, random_state=52, stratify=target)\n",
    "\n",
    "knn_a = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_a = GridSearchCV(knn_a, param_grid, cv=5)\n",
    "\n",
    "# train for all features:\n",
    "knn_cv_a.fit(X_train_a, y_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 19}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best parameter\n",
    "knn_cv_a.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83646672635034314"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best score\n",
    "knn_cv_a.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83900328260220824"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on training data to compare with score\n",
    "y_pred_all = knn_cv_a.predict(X_train_a)\n",
    "accuracy_all = knn_cv_a.score(X_train_a, y_train_a)\n",
    "accuracy_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83353221957040569"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_all = knn_cv_a.predict(X_test_a)\n",
    "accuracy_all = knn_cv_a.score(X_test_a, y_test_a)\n",
    "accuracy_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 2 attributes identified in EDA with major correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For 2 features\n",
    "\n",
    "two_3_1 = dating_data_clean[['attr3_1', 'fun3_1']]\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(two_3_1, target, test_size = 0.2, random_state=42, stratify=target)\n",
    "\n",
    "knn_2 = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_2 = GridSearchCV(knn_2, param_grid, cv=5)\n",
    "\n",
    "# train for 2 features:\n",
    "knn_cv_2.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 28}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83407937928976428"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_2 = knn_cv_2.predict(X_test_2)\n",
    "accuracy_2 = knn_cv_2.score(X_test_2, y_test_2)\n",
    "accuracy_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 1 attribute identified in EDA with major correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For 1 feature:\n",
    "\n",
    "one_3_1 = dating_data_clean[['attr3_1']]\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(one_3_1, target, test_size = 0.2, random_state=42, stratify=target)\n",
    "\n",
    "knn_1 = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_1 = GridSearchCV(knn_1, param_grid, cv=5)\n",
    "\n",
    "# train for all features:\n",
    "knn_cv_1.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 13}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83527305282005371"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cv_1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83412887828162297"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_1 = knn_cv_1.predict(X_test_1)\n",
    "accuracy_1 = knn_cv_1.score(X_test_1, y_test_1)\n",
    "accuracy_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conclusion: Two features (attractive and fun) performed better than the other options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Logistic regression as model to compare it with KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using all 5 attributes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 1.0000000000000001e-05}\n"
     ]
    }
   ],
   "source": [
    "## For all features:\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Create training and test sets\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(all_3_1, target, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X_train_a, y_train_a)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.8304814962196578\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score is {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 2 attributes identified in EDA with major correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 1.0000000000000001e-05}\n"
     ]
    }
   ],
   "source": [
    "## For 2 features:\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Create training and test sets\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(two_3_1, target, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg_2 = LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv_2 = GridSearchCV(logreg_2, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv_2.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.8304814962196578\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score is {}\".format(logreg_cv_2.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 1 attribute identified in EDA with major correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 1.0000000000000001e-05}\n"
     ]
    }
   ],
   "source": [
    "## For 1 feature:\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Create training and test sets\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(one_3_1, target, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg_1 = LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv_1 = GridSearchCV(logreg_1, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv_1.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv_1.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is 0.8304814962196578\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score is {}\".format(logreg_cv_1.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question to Andrei: discuss why all features have the same score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: knn performs better than logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Predicting based on important attributes at sign up for both participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same ranking used in item 1, but adding group of attributes ranked by both participants / couple. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using all 6 attributes for both participants (12 features):**\n",
    "\n",
    "A model with less features was not created based on result from previous models that indicated the score is higher with all the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = dating_data_clean[['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "## For all features:\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_fa, X_test_fa, y_train_fa, y_test_fa = train_test_split(features_all, target, test_size = 0.2, random_state=42, stratify=target)\n",
    "\n",
    "knn_fa = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_fa = GridSearchCV(knn_fa, param_grid, cv=5)\n",
    "\n",
    "# train for all features:\n",
    "knn_cv_fa.fit(X_train_fa, y_train_fa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 21}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best parameter\n",
    "knn_cv_fa.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83572068039391223"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best score\n",
    "knn_cv_fa.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83572068039391223"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on training data to compare with score\n",
    "y_pred_fa = knn_cv_fa.predict(X_train_fa)\n",
    "accuracy_fa = knn_cv_fa.score(X_train_fa, y_train_fa)\n",
    "accuracy_fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83591885441527447"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_test_fa = knn_cv_fa.predict(X_test_fa)\n",
    "accuracy_fa = knn_cv_fa.score(X_test_fa, y_test_fa)\n",
    "accuracy_fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conclusion: performs as well as using only one of the participants evaluation (item 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4) Predicting based on ratings the night of event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each participant ranked their dating with each partner based on 6 attributes (attractive, sincere, intelligent, ambitious, fun, shared interests) assigning a scale from 1 to 10.\n",
    "\n",
    "The code below predicts a match based on this ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using all 6 attributes for each of the partners (12 features):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_rat = dating_data_clean[['attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o']]\n",
    "target_rat = dating_data_clean['match']\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "## For all features:\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_rat, X_test_rat, y_train_rat, y_test_rat = train_test_split(features_rat, target_rat, test_size = 0.2, random_state=52, stratify=target_rat)\n",
    "\n",
    "knn_rat = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_rat = GridSearchCV(knn_rat, param_grid, cv=5)\n",
    "\n",
    "# train for all features:\n",
    "knn_cv_rat.fit(X_train_rat, y_train_rat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 28}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best parameter\n",
    "knn_cv_rat.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84079379289764244"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best score\n",
    "knn_cv_rat.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84601611459265891"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on training data to compare with score\n",
    "y_pred_rat = knn_cv_rat.predict(X_train_rat)\n",
    "accuracy_rat = knn_cv_rat.score(X_train_rat, y_train_rat)\n",
    "accuracy_rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83711217183770881"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_test_rat = knn_cv_rat.predict(X_test_rat)\n",
    "accuracy_test_rat = knn_cv_rat.score(X_test_rat, y_test_rat)\n",
    "accuracy_test_rat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 1 attribute (attractiveness):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_attr_rat = dating_data_clean[['attr', 'attr_o']]\n",
    "target_att_rat = dating_data_clean['match']\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "## For all features:\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_rat, X_test_rat, y_train_rat, y_test_rat = train_test_split(features_attr_rat, target_att_rat, test_size = 0.2, random_state=52, stratify=target_att_rat)\n",
    "\n",
    "knn_rat = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_rat = GridSearchCV(knn_rat, param_grid, cv=5)\n",
    "\n",
    "# train for all features:\n",
    "knn_cv_rat.fit(X_train_rat, y_train_rat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83412887828162297"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_test_rat = knn_cv_rat.predict(X_test_rat)\n",
    "accuracy_test_rat = knn_cv_rat.score(X_test_rat, y_test_rat)\n",
    "accuracy_test_rat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 1 attribute (shared interests):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_shar_rat = dating_data_clean[['shar', 'shar_o']]\n",
    "target_shar_rat = dating_data_clean['match']\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "## For all features:\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_rat, X_test_rat, y_train_rat, y_test_rat = train_test_split(features_shar_rat, target_shar_rat, test_size = 0.2, random_state=52, stratify=target_shar_rat)\n",
    "\n",
    "knn_rat = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_rat = GridSearchCV(knn_rat, param_grid, cv=5)\n",
    "\n",
    "# train for all features:\n",
    "knn_cv_rat.fit(X_train_rat, y_train_rat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83472553699284013"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_test_rat = knn_cv_rat.predict(X_test_rat)\n",
    "accuracy_test_rat = knn_cv_rat.score(X_test_rat, y_test_rat)\n",
    "accuracy_test_rat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 2 attributes (attractiveness and shared interests):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_shar_rat = dating_data_clean[['attr', 'attr_o', 'shar', 'shar_o']]\n",
    "target_shar_rat = dating_data_clean['match']\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "## For all features:\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_rat, X_test_rat, y_train_rat, y_test_rat = train_test_split(features_shar_rat, target_shar_rat, test_size = 0.2, random_state=52, stratify=target_shar_rat)\n",
    "\n",
    "knn_rat = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_rat = GridSearchCV(knn_rat, param_grid, cv=5)\n",
    "\n",
    "# train for all features:\n",
    "knn_cv_rat.fit(X_train_rat, y_train_rat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83233890214797135"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_test_rat = knn_cv_rat.predict(X_test_rat)\n",
    "accuracy_test_rat = knn_cv_rat.score(X_test_rat, y_test_rat)\n",
    "accuracy_test_rat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using 3 attributes (attractiveness, fun, shared interests):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_shar_rat = dating_data_clean[['attr', 'attr_o', 'shar', 'shar_o', 'fun', 'fun_o']]\n",
    "target_shar_rat = dating_data_clean['match']\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "## For all features'\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_rat, X_test_rat, y_train_rat, y_test_rat = train_test_split(features_shar_rat, target_shar_rat, test_size = 0.2, random_state=52, stratify=target_shar_rat)\n",
    "\n",
    "knn_rat = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_rat = GridSearchCV(knn_rat, param_grid, cv=5)\n",
    "\n",
    "# train for all features:\n",
    "knn_cv_rat.fit(X_train_rat, y_train_rat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83591885441527447"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_test_rat = knn_cv_rat.predict(X_test_rat)\n",
    "accuracy_test_rat = knn_cv_rat.score(X_test_rat, y_test_rat)\n",
    "accuracy_test_rat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: model has a better score when all features are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using all 6 attributes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## For all features:\n",
    "\n",
    "clf_a = MultinomialNB().fit(X_train_rat, y_train_rat)\n",
    "\n",
    "clf_a.score(X_test_rat, y_test_rat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_a = clf_a.predict(X_test_rat)\n",
    "accuracy_a = clf_a.score(X_test_rat, y_test_rat)\n",
    "accuracy_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 6, 'min_samples_leaf': 2}\n",
      "Best score is 0.8352730528200537\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "features_rat = dating_data_clean[['attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o']]\n",
    "target_rat = dating_data_clean['match']\n",
    "X_train_rat, X_test_rat, y_train_rat, y_test_rat = train_test_split(features_rat, target_rat, test_size = 0.2, random_state=52, stratify=target_rat)\n",
    "\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X_train_rat, y_train_rat)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8353221957040573"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_tree_rat = tree_cv.predict(X_test_rat)\n",
    "accuracy_tree_rat = tree_cv.score(X_test_rat, y_test_rat)\n",
    "accuracy_tree_rat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: KNN had a better score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Predicting based on 'like' scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each participant when asked if they liked the other participant in the date selected a number in a scale from 1 to 10. \n",
    "\n",
    "The code below predicts a match based on the like scale for both partners (2 features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_like = dating_data_clean[['like', 'like_o']]\n",
    "target_like = dating_data_clean['match']\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "k = [x for x in range(1,30)]\n",
    "param_grid = {'n_neighbors': k}\n",
    "\n",
    "## For all features:\n",
    "\n",
    "# Split into training and test set\n",
    "X_train_like, X_test_like, y_train_like, y_test_like = train_test_split(features_like, target_like, test_size = 0.2, random_state=52, stratify=target_like)\n",
    "\n",
    "knn_like = KNeighborsClassifier()\n",
    "\n",
    "knn_cv_like = GridSearchCV(knn_rat, param_grid, cv=5)\n",
    "\n",
    "# train for all features:\n",
    "knn_cv_like.fit(X_train_like, y_train_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 28}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best parameter\n",
    "knn_cv_like.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8488510892270964"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on training data to compare with score\n",
    "accuracy_like = knn_cv_like.score(X_train_like, y_train_like)\n",
    "accuracy_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84367541766109788"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "accuracy_test_like = knn_cv_like.score(X_test_like, y_test_like)\n",
    "accuracy_test_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings:\n",
    "\n",
    "Best features for predicting a match:\n",
    "\n",
    "    1) like scale collected during event after each date (score on test data: 0.8436)\n",
    "\n",
    "    2) evaluation of each date the time of event by both participants (score on test data: 0.8371)\n",
    "\n",
    "    3) 6 attributes important to participant at sign up (score on test data: 0.8359)\n",
    "\n",
    "    4) self evaluation of participant based on 2 attributes (attractiveness and fun) at sign up (score on test data: 0.8353)\n",
    "\n",
    "The above indicates that it's possible to predict with a good accuracy if a participant will have a match as soon as they sign up based on how important the attributes are to them and based on how they evaluate themselves.\n",
    "\n",
    "During the event, the predictions are more accurate based on how much they liked each other.\n",
    "\n",
    "Regarding the model, KNN classifier gave better scores than Naive Bayes, Logistic Classification or Decision Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
